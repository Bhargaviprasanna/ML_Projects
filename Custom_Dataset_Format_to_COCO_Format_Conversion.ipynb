{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom Dataset Format to COCO Format Conversion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDGLHTbTrucJ"
      },
      "source": [
        "# Conversion of Dataset to COCO Format\n",
        "\n",
        "In this notebook, we'll convert our Custom Dataset format to the COCO Format which can be used to train a model in Detectron2.\n",
        "\n",
        "- This dataset consists of 428 real images in the image folder. Annotation corresponding to image presents in Annotation folder. Out of which **401 images are used for training and the remaining 27 images are used for validation**. \n",
        "- The Annotation for the image has the same name that of the image just with the difference of extension. \n",
        "For example, if the image name is \"1.jpg\" then the corresponding annotation will be \"1.txt\".\n",
        "- The format for the storage of the annotation file is as such.\n",
        "- The no. of the lines in annotation text file denotes no of bounding box present in that image.\n",
        "- A single line represents a single bounding box. format is as follow x1, x2, x3, x4, y1, y2, y3, y4, Language. \n",
        "Where (x1,y1) is the top left, (x2,y2) is top right, (x3,y3) bottom right, (x4,y4) bottom left.\n",
        "- the order of point is in the clockwise order starting from the top-left points.\n",
        "\n",
        "\n",
        "You can download the dataset here: https://drive.google.com/file/d/1gZW8WiQz5UYPXo97nmcP7AI8dHH1yqPM/view?usp=sharing\n",
        "\n",
        "Upload it either to your session storage or upload it to your drive and mount your drive to this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxwi9aqozoPe"
      },
      "source": [
        "#If you did upload the zip file to your session storage, use this command or else modify accordingly.\n",
        "# !unzip \"/content/Text Detection Dataset.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FDn0BIpmU09"
      },
      "source": [
        "train_path = '/content/drive/MyDrive/datasets/Text_Detection/Text Detection Dataset/Train'\n",
        "test_path = '/content/drive/MyDrive/datasets/Text_Detection/Text Detection Dataset/Val'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86-6I08eMmL8",
        "outputId": "2dedf6eb-10d0-4659-f0b9-a03c071e89cb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtLWwkLQL5fA"
      },
      "source": [
        "## For Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCEebbg8WYsV"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "pd.set_option('display.max_colwidth', None) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqrrNC1P6FiN"
      },
      "source": [
        "main_result=pd.DataFrame(columns=[\"file_name\",\"height\",\"width\",\"annotations\"])\n",
        "main_result[\"annotations\"]=main_result[\"annotations\"].astype('object')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V49mmRV8jsT_"
      },
      "source": [
        "import os\n",
        "from natsort import natsorted\n",
        "os.chdir(train_path+\"/Annotations\")\n",
        "file_list =  natsorted(os.listdir())\n",
        "for i in natsorted(os.listdir()):\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7SsE2KddHuu"
      },
      "source": [
        "cat_dict = {\"HINDI\":\"0\",\"ENGLISH\":\"1\",\"OTHER\":\"2\"}\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# print(file_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7KF-tRZpjON"
      },
      "source": [
        "file_list\n",
        "# with open(file_list[0],'r') as f:\n",
        "#   y = f.readlines()\n",
        "# f.close()\n",
        "# y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyvJBrxvoh1m"
      },
      "source": [
        "### 0.txt has 3 boxes\n",
        "1. 122,294,295,126,207,214,277,270,HINDI\n",
        "2. 291,469,472,303,213,221,283,287,HINDI\n",
        "3. 464,581,581,473,214,221,287,281,HINDI\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JP2I8GTXIMHp",
        "outputId": "3f5b6b54-5ed0-4196-de50-3521654694ba"
      },
      "source": [
        "  # h = cv2.imread(train_path+'/0'+\".jpeg\").shape[:2]\n",
        "  f\"{train_path}/Images/{str(0)}.jpeg\"\n",
        "  /content/drive/MyDrive/datasets/Text_Detection/Text Detection Dataset/Train/Images/0.jpeg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/datasets/Text_Detection/Text Detection Dataset/Train/Images/0.jpeg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9zF_W31I_nT"
      },
      "source": [
        "# /content/drive/MyDrive/datasets/Text_Detection/Text Detection Dataset/Train/Images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEmI5vm_Wv9r"
      },
      "source": [
        "header_list = [\"x1\", \"x2\", \"x3\", \"x4\",\"y1\", \"y2\",\"y3\", \"y4\", \"category_id\"]\n",
        "\n",
        "k=0\n",
        "for i in file_list:\n",
        "  #collecting box data\n",
        "  # print(i)\n",
        "  df = pd.read_csv(i,header = None,index_col=False,names=header_list)\n",
        "  print(i)\n",
        "  df[\"height\"] = abs(df[\"y1\"]-df[\"y3\"])\n",
        "  df[\"width\"] = abs(df[\"x1\"]-df[\"x3\"])\n",
        "  df=df[[\"x1\",\"y1\",\"width\",\"height\",\"category_id\"]]\n",
        "  df1=df\n",
        "  \n",
        "  df1[\"bbox\"] = df1.iloc[:,0:4].values.tolist()\n",
        "  df1[\"bbox_mode\"] = 1\n",
        "  df1 = df1.replace({\"category_id\": cat_dict})\n",
        "  df1=df1[[\"bbox\",\t\"bbox_mode\",\t\"category_id\"]]\n",
        "  annotations = df1.T.to_dict().values()\n",
        "  l = []\n",
        "  for j in annotations:\n",
        "    l.append(j)\n",
        "  res=pd.DataFrame(columns=[\"file_name\",\"height\",\"width\",\"annotations\"])\n",
        "  res[\"annotations\"]=res[\"annotations\"].astype('object')\n",
        "  res.at[0,\"file_name\"] = i[:-4]+\".jpeg\"\n",
        "  res.at[0,\"annotations\"] = l\n",
        "  # h = cv2.imread(train_path+'/Images'+str(k)+\".jpeg\").shape[:2] \n",
        "  h = cv2.imread(f\"{train_path}/Images/{str(k)}.jpeg\").shape[:2]  \n",
        "  res.at[0,\"height\"] = h[0]\n",
        "  res.at[0,\"width\"] = h[1]\n",
        "  k=k+1\n",
        "  main_result = main_result.append(res)\n",
        "  main_result.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi1jp9y2GTOX"
      },
      "source": [
        "You'll see the Json file in the annotations folder of train data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7snlRpWL_SpC"
      },
      "source": [
        "main_result.reset_index(inplace=True)\n",
        "main_result.rename(columns={\"index\":\"image_id\"},inplace=True)\n",
        "main_result.to_json(\"dict_train.json\",orient=\"records\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX392LYwLxtG"
      },
      "source": [
        "## For Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA8DSATfLaTD"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-98LTYowLaTL"
      },
      "source": [
        "main_result=pd.DataFrame(columns=[\"file_name\",\"height\",\"width\",\"annotations\"])\n",
        "main_result[\"annotations\"]=main_result[\"annotations\"].astype('object')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfL5oblHLaTN"
      },
      "source": [
        "import os\n",
        "from natsort import natsorted\n",
        "os.chdir(test_path+\"/Annotations\")\n",
        "file_list =  natsorted(os.listdir())\n",
        "for i in natsorted(os.listdir()):\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNqhXjBQLaTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da862e71-12ef-4f08-a696-448a3290eb34"
      },
      "source": [
        "cat_dict = {\"HINDI\":\"0\",\"ENGLISH\":\"1\",\"OTHER\":\"2\"}\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "print(file_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['401.txt', '402.txt', '403.txt', '404.txt', '405.txt', '406.txt', '407.txt', '408.txt', '409.txt', '410.txt', '411.txt', '412.txt', '413.txt', '414.txt', '415.txt', '416.txt', '417.txt', '418.txt', '419.txt', '420.txt', '421.txt', '422.txt', '423.txt', '424.txt', '425.txt', '426.txt', '427.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z03GNdRLaTT"
      },
      "source": [
        "header_list = [\"x1\", \"x2\", \"x3\", \"x4\",\"y1\", \"y2\",\"y3\", \"y4\", \"category_id\"]\n",
        "\n",
        "k=401\n",
        "for i in file_list:\n",
        "  df = pd.read_csv(i,header = None,index_col=False,names=header_list)\n",
        "  df[\"height\"] = abs(df[\"y1\"]-df[\"y3\"])\n",
        "  df[\"width\"] = abs(df[\"x1\"]-df[\"x3\"])\n",
        "  df=df[[\"x1\",\"y1\",\"width\",\"height\",\"category_id\"]]\n",
        "  df1=df\n",
        "  \n",
        "  df1[\"bbox\"] = df1.iloc[:,0:4].values.tolist()\n",
        "  df1[\"bbox_mode\"] = 1\n",
        "  df1 = df1.replace({\"category_id\": cat_dict})\n",
        "  df1=df1[[\"bbox\",\t\"bbox_mode\",\t\"category_id\"]]\n",
        "  annotations = df1.T.to_dict().values()\n",
        "  l = []\n",
        "  for j in annotations:\n",
        "    l.append(j)\n",
        "  res=pd.DataFrame(columns=[\"file_name\",\"height\",\"width\",\"annotations\"])\n",
        "  res[\"annotations\"]=res[\"annotations\"].astype('object')\n",
        "  res.at[0,\"file_name\"] = i[:-4] + \".jpeg\"\n",
        "  res.at[0,\"annotations\"] = l\n",
        "  h = cv2.imread(\"../Images/\"+str(k)+\".jpeg\").shape[:2]\n",
        "  res.at[0,\"height\"] = h[0]\n",
        "  res.at[0,\"width\"] = h[1]\n",
        "  k=k+1\n",
        "  main_result = main_result.append(res)\n",
        "  main_result.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxYWW1RRLaTW"
      },
      "source": [
        "\n",
        "main_result.reset_index(inplace=True)\n",
        "main_result.rename(columns={\"index\":\"image_id\"},inplace=True)\n",
        "main_result.to_json(\"dict_val.json\",orient=\"records\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "rWCrgNP70stu",
        "outputId": "032e0811-05b1-4a73-fea1-5654f4b78dfe"
      },
      "source": [
        "!pip install coco-assistant"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting coco-assistant\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/63/13e07f570402bdd1cc940e516e3535369f64c712c0d6c056cf1a165614fb/coco_assistant-0.3.4-py3-none-any.whl\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from coco-assistant) (0.29.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from coco-assistant) (4.41.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from coco-assistant) (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from coco-assistant) (0.11.1)\n",
            "Requirement already satisfied: setuptools>=40.6.3 in /usr/local/lib/python3.7/dist-packages (from coco-assistant) (54.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from coco-assistant) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from coco-assistant) (1.1.5)\n",
            "Collecting Pillow>=8.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/34/542152297dcc6c47a9dcb0685eac6d652d878ed3cea83bf2b23cb988e857/Pillow-8.2.0-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 14.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from coco-assistant) (2.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from coco-assistant) (0.16.2)\n",
            "Requirement already satisfied: wheel>=0.32.3 in /usr/local/lib/python3.7/dist-packages (from coco-assistant) (0.36.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->coco-assistant) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->coco-assistant) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->coco-assistant) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->coco-assistant) (2.4.7)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn->coco-assistant) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->coco-assistant) (2018.9)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->coco-assistant) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->coco-assistant) (2.5)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->coco-assistant) (1.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->coco-assistant) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->coco-assistant) (4.4.2)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow, coco-assistant\n",
            "  Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "Successfully installed Pillow-8.2.0 coco-assistant-0.3.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ELioFyh1ehq"
      },
      "source": [
        "import os\n",
        "from coco_assistant import COCO_Assistant\n",
        "\n",
        "# Specify image and annotation directories\n",
        "img_path = '/content/drive/MyDrive/datasets/sample_merging/images'\n",
        "ann_path = '/content/drive/MyDrive/datasets/sample_merging/annotations'\n",
        "img_dir = os.path.join(os.getcwd(), img_path)\n",
        "ann_dir = os.path.join(os.getcwd(), ann_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGKlg9rr0spT",
        "outputId": "70b66040-cec7-4921-9c83-6371e0afe599"
      },
      "source": [
        "cas = COCO_Assistant(img_dir, ann_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsJTROCp0snt"
      },
      "source": [
        "dir(cas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtQKSTlnLPEF"
      },
      "source": [
        "cas.merge(merge_images=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN1FIlBoPY-B"
      },
      "source": [
        "def merge(self, merge_images=True):\n",
        "        \"\"\"\n",
        "        Function for merging multiple coco datasets\n",
        "        \"\"\"\n",
        "\n",
        "        self.resim_dir = os.path.join(self.res_dir, \"merged\", \"images\")\n",
        "        self.resann_dir = os.path.join(self.res_dir, \"merged\", \"annotations\")\n",
        "\n",
        "        # Create directories for merged results and clear the previous ones\n",
        "        # The exist_ok is for dealing with merged folder\n",
        "        # TODO: Can be done better\n",
        "        if os.path.exists(self.resim_dir) is False:\n",
        "            os.makedirs(self.resim_dir, exist_ok=True)\n",
        "        else:\n",
        "            shutil.rmtree(self.resim_dir)\n",
        "            os.makedirs(self.resim_dir, exist_ok=True)\n",
        "        if os.path.exists(self.resann_dir) is False:\n",
        "            os.makedirs(self.resann_dir, exist_ok=True)\n",
        "        else:\n",
        "            shutil.rmtree(self.resann_dir)\n",
        "            os.makedirs(self.resann_dir, exist_ok=True)\n",
        "\n",
        "        if merge_images:\n",
        "            print(\"Merging image dirs\")\n",
        "            im_dirs = [os.path.join(self.img_dir, folder) for folder in self.imgfolders]\n",
        "            imext = [\".png\", \".jpg\"]\n",
        "\n",
        "            logging.debug(\"Merging Image Dirs...\")\n",
        "\n",
        "            for imdir in tqdm(im_dirs):\n",
        "                ims = [i for i in os.listdir(imdir) if i[-4:].lower() in imext]\n",
        "                for im in ims:\n",
        "                    shutil.copyfile(os.path.join(imdir, im), os.path.join(self.resim_dir, im))\n",
        "\n",
        "        else:\n",
        "            logging.debug(\"Not merging Image Dirs...\")\n",
        "\n",
        "        cann = {\"images\": [], \"annotations\": [], \"info\": None, \"licenses\": None, \"categories\": None}\n",
        "\n",
        "        logging.debug(\"Merging Annotations...\")\n",
        "\n",
        "        dst_ann = os.path.join(self.resann_dir, \"merged.json\")\n",
        "\n",
        "        print(\"Merging annotations\")\n",
        "        for j in tqdm(self.jsonfiles):\n",
        "            with open(os.path.join(self.ann_dir, j)) as a:\n",
        "                cj = json.load(a)\n",
        "\n",
        "            ind = self.jsonfiles.index(j)\n",
        "            # Check if this is the 1st annotation.\n",
        "            # If it is, continue else modify current annotation\n",
        "            if ind == 0:\n",
        "                cann[\"images\"] = cann[\"images\"] + cj[\"images\"]\n",
        "                cann[\"annotations\"] = cann[\"annotations\"] + cj[\"annotations\"]\n",
        "                if \"info\" in list(cj.keys()):\n",
        "                    cann[\"info\"] = cj[\"info\"]\n",
        "                if \"licenses\" in list(cj.keys()):\n",
        "                    cann[\"licenses\"] = cj[\"licenses\"]\n",
        "                cann[\"categories\"] = sorted(cj[\"categories\"], key=lambda i: i[\"id\"])\n",
        "\n",
        "                last_imid = cann[\"images\"][-1][\"id\"]\n",
        "                last_annid = cann[\"annotations\"][-1][\"id\"]\n",
        "\n",
        "                # If last imid or last_annid is a str, convert it to int\n",
        "                if isinstance(last_imid, str) or isinstance(last_annid, str):\n",
        "                    logging.debug(\"String Ids detected. Converting to int\")\n",
        "                    id_dict = {}\n",
        "                    # Change image id in images field\n",
        "                    for i, im in enumerate(cann[\"images\"]):\n",
        "                        id_dict[im[\"id\"]] = i\n",
        "                        im[\"id\"] = i\n",
        "\n",
        "                    # Change annotation id & image id in annotations field\n",
        "                    for i, im in enumerate(cann[\"annotations\"]):\n",
        "                        im[\"id\"] = i\n",
        "                        if isinstance(last_imid, str):\n",
        "                            im[\"image_id\"] = id_dict[im[\"image_id\"]]\n",
        "\n",
        "                last_imid = cann[\"images\"][-1][\"id\"]\n",
        "                last_annid = cann[\"annotations\"][-1][\"id\"]\n",
        "\n",
        "            else:\n",
        "\n",
        "                id_dict = {}\n",
        "                # Change image id in images field\n",
        "                for i, im in enumerate(cj[\"images\"]):\n",
        "                    id_dict[im[\"id\"]] = last_imid + i + 1\n",
        "                    im[\"id\"] = last_imid + i + 1\n",
        "\n",
        "                # Change annotation and image ids in annotations field\n",
        "                for i, ann in enumerate(cj[\"annotations\"]):\n",
        "                    ann[\"id\"] = last_annid + i + 1\n",
        "                    ann[\"image_id\"] = id_dict[ann[\"image_id\"]]\n",
        "\n",
        "                # Remap categories\n",
        "                cmapper = CatRemapper(cann[\"categories\"], cj[\"categories\"])\n",
        "                cann[\"categories\"], cj[\"annotations\"] = cmapper.remap(cj[\"annotations\"])\n",
        "\n",
        "                cann[\"images\"] = cann[\"images\"] + cj[\"images\"]\n",
        "                cann[\"annotations\"] = cann[\"annotations\"] + cj[\"annotations\"]\n",
        "                if \"info\" in list(cj.keys()):\n",
        "                    cann[\"info\"] = cj[\"info\"]\n",
        "                if \"licenses\" in list(cj.keys()):\n",
        "                    cann[\"licenses\"] = cj[\"licenses\"]\n",
        "\n",
        "                last_imid = cann[\"images\"][-1][\"id\"]\n",
        "                last_annid = cann[\"annotations\"][-1][\"id\"]\n",
        "\n",
        "        with open(dst_ann, \"w\") as aw:\n",
        "            json.dump(cann, aw)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}